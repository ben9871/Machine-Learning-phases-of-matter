{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fa4b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08060d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.000000000000000000e+01\\n', '2.000000000000000000e+01\\n', '3.000000000000000000e+01\\n', '4.000000000000000000e+01\\n', '5.000000000000000000e+01\\n', '6.000000000000000000e+01\\n']\n",
      "1, 2, 3, 4, 5, 6\n",
      "[10, 20, 30, 40, 50, 60]\n"
     ]
    }
   ],
   "source": [
    "L=[]\n",
    "with open(\"lattice_sizes.txt\") as f:\n",
    "        L = f.readlines()\n",
    "print(L) \n",
    "# take lattice list in text file and reread it into list\n",
    "\n",
    "modified_strings = [s.replace('e+01\\n', '') for s in L]\n",
    "integers = [int(float(s)) for s in modified_strings]\n",
    "#convert scientific notation strings into integers\n",
    "\n",
    "result = ', '.join(str(i) for i in integers)\n",
    "print(result)\n",
    "L=[]\n",
    "for i in (integers):\n",
    "    L.append(i*10)\n",
    "print(L)    \n",
    "\n",
    "# multiply by 10 so as to return the original lattice sizes in increments of ten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3eedf059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files =[]\n",
    "for k,i in enumerate(L):\n",
    "    a = np.load('data_lattice_new{}.npz'.format(i))\n",
    "    files.append(a)\n",
    "    \n",
    "# load all data files for lattice sizes\n",
    "# all the files conveniently have lattice size at the end so can be called according to such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36d3a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (26000, 10, 10)\n",
      "y.shape: (26000,)\n",
      "(22000, 10, 10)\n",
      "(22000,)\n",
      "X.shape: (26000, 20, 20)\n",
      "y.shape: (26000,)\n",
      "(22000, 20, 20)\n",
      "(22000,)\n",
      "X.shape: (26000, 30, 30)\n",
      "y.shape: (26000,)\n",
      "(22000, 30, 30)\n",
      "(22000,)\n",
      "X.shape: (26000, 40, 40)\n",
      "y.shape: (26000,)\n",
      "(22000, 40, 40)\n",
      "(22000,)\n",
      "X.shape: (26000, 50, 50)\n",
      "y.shape: (26000,)\n",
      "(22000, 50, 50)\n",
      "(22000,)\n",
      "X.shape: (26000, 60, 60)\n",
      "y.shape: (26000,)\n",
      "(22000, 60, 60)\n",
      "(22000,)\n"
     ]
    }
   ],
   "source": [
    "Xtrains = []\n",
    "Xtests = []\n",
    "Ytrains =[]\n",
    "Ytests =[]\n",
    "\n",
    "# empty lists to which we shall append\n",
    "\n",
    "for k, i in enumerate(files):\n",
    "\n",
    "    print('X.shape:', i['lattices'].shape)\n",
    "    print('y.shape:', i['temperatures'].shape)\n",
    "    #check the data we have\n",
    "    \n",
    "    X_train, X_test= np.split(i['lattices'], [22000])\n",
    "    Y_train, Y_test =  np.split(i['temperatures'], [22000])\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    # for 26000 lattices we split at 22000 into training and test sets\n",
    "    Xtrains.append(X_train)\n",
    "    Xtests.append(X_test)\n",
    "    Ytrains.append(Y_train)\n",
    "    Ytests.append(Y_test)\n",
    "    \n",
    "    #append split data to empty lists for each lattice size\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cfb3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_onehot(y_label, n_classes):\n",
    "    if np.min(y_label) < 0 or np.max(y_label) >= n_classes:\n",
    "        print('Error: n_classes not compatible with label_vector')\n",
    "        return None\n",
    "    y_onehot = np.zeros((len(y_label), n_classes))\n",
    "    y_onehot[np.arange(len(y_label)), y_label] = 1 \n",
    "    return y_onehot\n",
    "# this shall be used upon the temperatures. a onehot labelling system\n",
    "#representing probability of being ferromagnetic or paramagnetic\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d98f45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22000, 2)\n",
      "(4000, 2)\n",
      "(22000, 2)\n",
      "(4000, 2)\n",
      "(22000, 2)\n",
      "(4000, 2)\n",
      "(22000, 2)\n",
      "(4000, 2)\n",
      "(22000, 2)\n",
      "(4000, 2)\n",
      "(22000, 2)\n",
      "(4000, 2)\n"
     ]
    }
   ],
   "source": [
    "N_samples = int((3.6-1)/0.1)\n",
    "temperatures = np.linspace(1.0, 3.6, N_samples)\n",
    "Tc = 2.27\n",
    "n_temps = len(temperatures)\n",
    "# make sure all relevant temperature details are known. \n",
    "# perhaps these will also be made into a textfile format for better user ease at some point\n",
    "\n",
    "ytrains = []\n",
    "ytests = []\n",
    "# empty lists to append newly labeled ytrain and ytest sets\n",
    "\n",
    "for k, i in enumerate(files):\n",
    "    y_train = Ytrains[k] > Tc\n",
    "    y_train = label_to_onehot(y_train.astype(int), 2)\n",
    "    # onehot encoding for ytrains\n",
    "    \n",
    "    y_test = Ytests[k] > Tc\n",
    "    y_test = label_to_onehot(y_test.astype(int), 2)\n",
    "    #onehot encoding for ytests\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    # verify the data by printing shape\n",
    "    \n",
    "    ytrains.append(y_train)\n",
    "    ytests.append(y_test)\n",
    "    # as usual we append the lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e095eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, i in enumerate(L):\n",
    "\n",
    "    np.savez_compressed('X_tests_{} '.format(i), lats = Xtests[k])\n",
    "    np.savez_compressed('X_trains_{} '.format(i), lats = Xtrains[k])\n",
    "    np.savez_compressed('y_tests_{} '.format(i), onehots = ytests[k])\n",
    "    np.savez_compressed('y_trains_{} '.format(i), onehots = ytrains[k])\n",
    "    np.savez_compressed('Yor_tests_{} '.format(i), temps = Ytests[k])\n",
    "    np.savez_compressed('Yor_trains_{} '.format(i), temps = Ytrains[k])\n",
    "    \n",
    "# save these encoded test sets and the training sets to new files( denoted with Y and X)\n",
    "# save the unencoded versions with Yor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c35cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
